{
    "video_id": "k0dsWsmsLWM",
    "summary": "{\n  \"executive_summary\": \"Learning data structures and algorithms (DSNA) is still relevant in 2026, especially for junior to mid-level roles. The author shares their experience of learning DSNA and practicing over the years to get dozens of offers at top tech companies. They recommend a specific progression of topics to learn, starting with arrays and hashmaps, then building up through stacks, linked lists, trees, heaps, priority queues, graphs, and dynamic programming.\",\n  \"key_points\": [\n    \"Learning DSNA is still relevant in 2026, especially for junior to mid-level roles.\",\n    \"The author recommends a specific progression of topics to learn: arrays and hashmaps, then building up through stacks, linked lists, trees, heaps, priority queues, graphs, and dynamic programming.\",\n    \"The author suggests practicing with problems and using resources such as LeetCode, Node 150, and MIT Open Courseware to learn DSNA.\",\n    \"The author emphasizes the importance of practicing and knowing the fundamentals well to accelerate job search and career.\"\n  ],\n  \"action_items\": [\n    \"Start with arrays and hashmaps\",\n    \"Build up through stacks, linked lists, trees, heaps, priority queues, graphs, and dynamic programming\",\n    \"Practice with problems on LeetCode, Node 150, and other resources\",\n    \"Use AI as a study partner, not just a solution generator\"\n  ],\n  \"topics\": [\n    \"Arrays\",\n    \"Hashmaps\",\n    \"Stacks\",\n    \"Linked lists\",\n    \"Trees\",\n    \"Heaps\",\n    \"Priority queues\",\n    \"Graphs\",\n    \"Dynamic programming\"\n  ]\n}",
    "transcript": "If you find coding problems unintuitive or you're wondering if it's even worth it to learn data structures and algorithms in 2026, you are not alone. Most people approach DSNA in a very inefficient way, watching hours of tutorials, reading textbook chapters, and memorizing definitions. But the moment they open le code, they freeze. I know because this was me when I was a student. Hi friends, I'm Maddie. I'm a senior software engineer who previously worked at Google and internet IBM, Amazon, and Microsoft. I learned [music] DSNA and practiced over the years to get dozens of offers at top tech companies, and I've been on both sides of the interview table. In this video, I'll share exactly how I went from struggling with basic array problems to confidently solving mediums, being able to solve hards, and passing big tech interviews. We'll cover why data structure algorithms actually matter in 2026, the exact progression from simpler algorithms topics like arrays to advanced topics like graphs and dynamic programming, and the specific resources I'd use if I was starting all over today. Let's get into it. First, let's talk about why studying data structures algorithms is still even relevant in 2026. It might seem like le code is obsolete. For example, Meta just rolled out AI enabled coding interviews where you are allowed to use Claude or TPT sitting next to you. However, many big tech employers continue to use traditional DSNA leak code questions as part of their interview funnel, especially in early rounds and for junior to mid-level roles. Google has even doubled down, actively reintroducing in-person interview rounds in response to AI assisted cheating and the challenges of evaluating candidates remotely. Even the companies that are introducing AI enabled coding interviews often have kept at least one [music] or two leak code style coding challenge rounds. Also, what I learned from actually working inside these big tech companies is that the fundamentals have not changed. [music] Yes, AI can solve a twosome problem. But AI can't walk an interviewer through your thought process, adapt when they throw a curveball, or demonstrate the problem-solving intuition that separates a good engineer from a great one. Interviewers are evaluating you not just on the correctness of your solution, but the thinking that you demonstrate to arrive at that solution. The biggest change in my strategy that I did throughout the years [music] was practice first, theory later. When I started studying algorithms for the first time in college, I made a classic mistake. I tried to learn all the theory before touching any actual problems. I would read the CLRS textbook, watch lecture recordings, take detailed notes, and then when I finally sat down to code, I had no idea where to start. It's like trying to learn how to play the piano by studying music theory for 6 months before ever touching the instrument. You might understand chord progressions intellectually, but your fingers won't know what to do. So, what I'm saying is that you should pick up a problem, struggle with it for 20 to 30 minutes, and only then look at the solution. I also actively scheduled interviews for companies that I didn't necessarily think I would actually accept offers from just for more interview practice and to get used to walking through my problemsolving process and talking to a real interviewer. Now, let me walk you through the exact progression I'd follow if I were starting from scratch in 2026. This is roughly the order that MIT's 6006 algorithms class covers things and I think that it is the order that makes the most sense for building concepts on top of each other. The first concepts to learn is arrays and strings. This is where everyone starts and honestly it is where you should sink a lot of time. Arrays are the foundation of everything. If you can't manipulate arrays confidently, you'll struggle with every single topic that follows. The key patterns to master here are two pointers and sliding window. Twop pointer is perfect for problems like finding pairs that sum up to a target or removing duplicates from a sorted array. Sliding window helps with substring problems and finding maximum sums in subarrays. A problem I always recommend starting with is to sum. You're given an array of numbers and a target number. Your goal is to find two different elements in the array that add up to the target and return their indices. It's one of Leode's most famous problems for a reason. It teaches you to think about time complexity trade-offs. The brute force solution is Oven squared, but with a hashmap you get O of N. Speaking of which, next study hashmaps and sets. Hashmaps are quite important because they give you O1 lookup time, which unlocks so many optimizations. At Google, I used hashmaps constantly, whether it was caching computer results, counting frequencies, or building lookup tables. Sets are closely related. They're basically hashmaps where you only care about the keys. They're useful for tracking unique elements, or checking membership quickly. Classic problems to practice include valid anagram, which asks whether two strings contain the exact same characters in the same quantities regardless of order, and top k frequent elements, which asks about the k numbers that appear most often in a given list. [music] These two problems will drill the pattern into your brain. Next, let's move on to stacks and Q's. Stacks follow a simple principle. Last in, first out. Think of a stack of plates. The last plate you put on is the first one you take off. Q's are the opposite. First in, first out, like a line at a coffee shop. These structures are crucial for recursion problems, expression evaluation, and breath for search. A classic stack problem everyone should solve is valid parenthesis, where you're checking to see if brackets in a string are properly opened, closed, and nested. For cues, you can try implementing a recent calls counter or a moving average calculator. Next up, we have linked lists. Unlike arrays, you can't just index into [music] linked lists. You have to traverse node by node. Once you understand pointer manipulation, they become pretty intuitive. The most common patterns to know are the fast and slow pointer technique for cycle detection and recursive versus iterative reversal. Reverse linked list is a problem that you should be able to solve in your sleep. Next, let's move on to trees and BSTs. A tree is just nodes connected by edges with a root at the top and leaves at the bottom. Binary trees restrict each node to at most two children and [music] BSTs or binary search trees at the property that left children are smaller and right children are larger. You need to be very comfortable with all three traversals: in order, pre-order, and post-order. In order gives you sorted order in a BST. Pre-order is great for copying trees. Post-order works well for bottom-up calculations like finding heights. AVL trees are pretty uncommon in interviews, but you should know generally what they are. Next up, we have heaps and priority cues. A heap is a special tree with the parent is always greater than or less than its children. This gives you 01 access to the maximum or [music] minimum element and of log and insertion and deletion. keeps power priority cues which are everywhere in real systems. For example, in task scheduling, event processing, and finding the k largest elements. Next up, we have graphs. Graphs are one of the most complex data structures. A graph is a collection of nodes connected by edges, but those edges can be directed or undirected, weighted or unweed, cyclic or asyclic. The two fundamental traversal algorithms are breath for search and death for search. [music] BFS or breath for search is perfect for shortest path problems in unweighted graphs while DFS or depth for search is great for detecting cycles, exploring all possible paths or working with connected components. So many problems in the world are actually graph problems. For example, social networks, rooting, dependency resolution, even web crawling. And last but not least, we have dynamic programming or DP. Dynamic programming sounds [music] scary, but fundamentally it's just a fancy way to say recursion with memorization. You break a problem into smaller sub problems, solve each sub problem once and [music] store the results. So for example, you can start with the classics climbing stairs, house robber, coin change. These problems teach you to identify overlapping sub problems and optimal substructure. From there, you can work up to 2D DP problems like longest common subsequence. So now that you know the core topics to cover, [music] I'm going to give you the exact resources I use to study these in 2026. First, for structured learning, Node 150 is amazing. It is a curated list of 150 le code problems organized by topic and difficulty created by a former Google engineer. It is a super set of le code75 which I'd recommend if you have less time for video explanations. Neat code on YouTube is fantastic. Abdari is another incredible resource. His explanations of algorithms are some of the clearest I've ever seen, especially for topics like dynamic programming and graph algorithms. And if you want the academic foundation, MIT Open Courseware 66 lectures from 2020 with Eric Demain are excellent. I also recommend reading through cracking the coding interview and working through their examples. [music] And for the basics, I'd recommend skimming through CLS. For written explanations and practice, I love Geek for Geeks. They have articles on literally every single DSNA topic with code examples in multiple languages. And make sure that you're using AI as a study partner, not just a solution generator. When you're stuck, ask Claude or Tat or Gemini to give you a hint about which data structure to consider, not the full solution. Ask it to explain why a certain approach is ON instead of O N squared. Use it to generate edge cases for your solution. That's how you can use AI to actually accelerate your learning instead of just copying blindly. So, in conclusion, in order to learn DSNA fast and effectively, start with arrays and hashmaps, build up through stacks, link list entries, and then tackle advanced stuff like graphs and dynamic programming. [music] And look, even though learning DSNA isn't easy, I promise you that it gets easier and easier with practice and knowing the fundamentals well will accelerate your job search and career. And that's all I have for you in this video. If you found this helpful, please hit that like button, hype this video, and subscribe for more software engineering content. Thanks for watching, and I'll see you in the next one.",
    "metadata": {},
    "cached_at": "2026-02-17T21:32:47.254189"
}